import Foundation
import AVFoundation
import SwiftUI

class CameraManager: NSObject, ObservableObject {
    @Published var isRecording = false
    @Published var recordingTime: TimeInterval = 0
    @Published var hasPermission = false
    
    let captureSession = AVCaptureSession()
    private var videoOutput: AVCaptureMovieFileOutput?
    private var currentVideoInput: AVCaptureDeviceInput?
    private var recordingTimer: Timer?
    private var outputURL: URL?
    
    var formattedRecordingTime: String {
        let minutes = Int(recordingTime) / 60
        let seconds = Int(recordingTime) % 60
        return String(format: "%02d:%02d", minutes, seconds)
    }
    
    override init() {
        super.init()
        // Don't setup session until we have permission
    }
    
    func checkPermission() {
        print("ðŸŽ¥ Checking camera permission...")
        let status = AVCaptureDevice.authorizationStatus(for: .video)
        print("ðŸŽ¥ Current permission status: \(status.rawValue)")
        
        switch status {
        case .authorized:
            print("âœ… Camera permission already granted")
            DispatchQueue.main.async {
                self.hasPermission = true
                self.setupSession()
                // Start session immediately after setup when permission is already granted
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
                    self.startSession()
                }
            }
        case .notDetermined:
            print("â“ Requesting camera permission...")
            AVCaptureDevice.requestAccess(for: .video) { granted in
                print("ðŸŽ¥ Permission request result: \(granted)")
                DispatchQueue.main.async {
                    self.hasPermission = granted
                    if granted {
                        print("âœ… Permission granted, setting up camera...")
                        self.setupSession()
                        // Start session after setup when permission is newly granted
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
                            self.startSession()
                        }
                    } else {
                        print("âŒ Camera permission denied")
                    }
                }
            }
        case .denied, .restricted:
            print("âŒ Camera permission denied or restricted")
            DispatchQueue.main.async {
                self.hasPermission = false
            }
        @unknown default:
            DispatchQueue.main.async {
                self.hasPermission = false
            }
        }
    }
    
    private func setupSession() {
        // Only setup session if we have permission
        guard hasPermission else {
            print("âš ï¸ Cannot setup camera session without permission")
            return
        }
        
        print("ðŸ”§ Setting up camera session...")
        captureSession.sessionPreset = .high
        
        // Add video input
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back),
              let videoInput = try? AVCaptureDeviceInput(device: videoDevice) else {
            print("âŒ Failed to create video input device")
            return
        }
        
        print("ðŸ“¹ Created video input device")
        
        if captureSession.canAddInput(videoInput) {
            captureSession.addInput(videoInput)
            currentVideoInput = videoInput
            print("âœ… Added video input to session")
        } else {
            print("âŒ Cannot add video input to session")
            return
        }
        
        // Add audio input
        if let audioDevice = AVCaptureDevice.default(for: .audio),
           let audioInput = try? AVCaptureDeviceInput(device: audioDevice) {
            if captureSession.canAddInput(audioInput) {
                captureSession.addInput(audioInput)
                print("âœ… Added audio input to session")
            } else {
                print("âš ï¸ Cannot add audio input to session - continuing without audio")
            }
        } else {
            print("âš ï¸ Failed to create audio input device - continuing without audio")
        }
        
        // Add video output
        let movieOutput = AVCaptureMovieFileOutput()
        if captureSession.canAddOutput(movieOutput) {
            captureSession.addOutput(movieOutput)
            videoOutput = movieOutput
            print("âœ… Added video output to session")
            
            // Configure video settings for better compatibility
            if let connection = movieOutput.connection(with: .video) {
                // Enable video stabilization if available
                if connection.isVideoStabilizationSupported {
                    connection.preferredVideoStabilizationMode = .auto
                    print("âœ… Enabled video stabilization")
                }
                
                // Set preferred video orientation
                if #available(iOS 17.0, *) {
                    if connection.isVideoRotationAngleSupported(0) {
                        connection.videoRotationAngle = 0 // Portrait orientation
                        print("âœ… Set video rotation angle to 0Â° (portrait)")
                    }
                } else {
                    if connection.isVideoOrientationSupported {
                        connection.videoOrientation = .portrait
                        print("âœ… Set video orientation to portrait")
                    }
                }
            }
            
            // Configure output settings for better server compatibility
            movieOutput.movieFragmentInterval = CMTime.invalid // Disable fragmentation for compatibility
            print("âœ… Configured video output settings for server compatibility")
            
        } else {
            print("âŒ Cannot add video output to session")
        }
        
        print("ðŸŽ¬ Camera session setup complete")
    }
    
    func startSession() {
        guard !captureSession.isRunning else { 
            print("ðŸ“¹ Session already running")
            return 
        }
        
        guard hasPermission else {
            print("âš ï¸ Cannot start session without camera permission")
            return
        }
        
        guard captureSession.inputs.count > 0 else {
            print("âš ï¸ Cannot start session without camera inputs")
            return
        }
        
        print("â–¶ï¸ Starting camera session...")
        DispatchQueue.global(qos: .userInitiated).async {
            self.captureSession.startRunning()
            DispatchQueue.main.async {
                print("âœ… Camera session started successfully - isRunning: \(self.captureSession.isRunning)")
            }
        }
    }
    
    func stopSession() {
        guard captureSession.isRunning else { 
            print("ðŸ“¹ Session already stopped")
            return 
        }
        
        print("â¹ï¸ Stopping camera session...")
        DispatchQueue.global(qos: .background).async {
            self.captureSession.stopRunning()
            DispatchQueue.main.async {
                print("âœ… Camera session stopped - isRunning: \(self.captureSession.isRunning)")
            }
        }
    }
    
    func debugSessionStatus() {
        print("ðŸ” === Camera Session Debug ===")
        print("ðŸ“¹ Has permission: \(hasPermission)")
        print("ðŸ“¹ Session running: \(captureSession.isRunning)")
        print("ðŸ“¹ Session inputs: \(captureSession.inputs.count)")
        print("ðŸ“¹ Session outputs: \(captureSession.outputs.count)")
        print("ðŸ“¹ Session preset: \(captureSession.sessionPreset.rawValue)")
        
        for (index, input) in captureSession.inputs.enumerated() {
            if let deviceInput = input as? AVCaptureDeviceInput {
                print("ðŸ“¹ Input \(index): \(deviceInput.device.localizedName) - Position: \(deviceInput.device.position.rawValue)")
            }
        }
        
        for (index, output) in captureSession.outputs.enumerated() {
            print("ðŸ“¹ Output \(index): \(type(of: output))")
        }
        print("ðŸ” === End Debug ===")
    }
    
    func startRecording() {
        guard let videoOutput = videoOutput, !videoOutput.isRecording else { return }
        
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let outputURL = documentsPath.appendingPathComponent("swing_video_\(Date().timeIntervalSince1970).mp4")
        self.outputURL = outputURL
        
        videoOutput.startRecording(to: outputURL, recordingDelegate: self)
        
        // Start timer
        recordingTime = 0
        recordingTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            DispatchQueue.main.async {
                self.recordingTime += 0.1
            }
        }
        
        DispatchQueue.main.async {
            self.isRecording = true
        }
    }
    
    func stopRecording(completion: @escaping (Data?) -> Void) {
        guard let videoOutput = videoOutput, videoOutput.isRecording else {
            completion(nil)
            return
        }
        
        videoOutput.stopRecording()
        recordingTimer?.invalidate()
        recordingTimer = nil
        
        DispatchQueue.main.async {
            self.isRecording = false
            self.recordingTime = 0
        }
        
        // Store completion for use in delegate
        self.recordingCompletion = completion
    }
    
    private var recordingCompletion: ((Data?) -> Void)?
    
    func flipCamera() {
        guard let currentInput = currentVideoInput else { return }
        
        let currentPosition = currentInput.device.position
        let newPosition: AVCaptureDevice.Position = currentPosition == .back ? .front : .back
        
        guard let newDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: newPosition),
              let newInput = try? AVCaptureDeviceInput(device: newDevice) else {
            return
        }
        
        captureSession.beginConfiguration()
        captureSession.removeInput(currentInput)
        
        if captureSession.canAddInput(newInput) {
            captureSession.addInput(newInput)
            currentVideoInput = newInput
        }
        
        captureSession.commitConfiguration()
    }
}

// MARK: - AVCaptureFileOutputRecordingDelegate

extension CameraManager: AVCaptureFileOutputRecordingDelegate {
    func fileOutput(_ output: AVCaptureFileOutput, didFinishRecordingTo outputFileURL: URL, from connections: [AVCaptureConnection], error: Error?) {
        if let error = error {
            print("âŒ Recording error: \(error)")
            recordingCompletion?(nil)
        } else {
            print("âœ… Recording completed successfully")
            print("ðŸ“¹ Video file URL: \(outputFileURL)")
            
            // Get video file attributes
            do {
                let attributes = try FileManager.default.attributesOfItem(atPath: outputFileURL.path)
                if let fileSize = attributes[.size] as? Int64 {
                    print("ðŸ“¹ Video file size: \(fileSize) bytes")
                }
            } catch {
                print("âš ï¸ Could not get file attributes: \(error)")
            }
            
            // Convert video file to Data
            do {
                let videoData = try Data(contentsOf: outputFileURL)
                print("ðŸ“¹ Video data loaded: \(videoData.count) bytes")
                
                // Check video file type by reading header
                if videoData.count > 8 {
                    let header = videoData.prefix(8)
                    let headerString = header.map { String(format: "%02x", $0) }.joined()
                    print("ðŸ“¹ Video file header: \(headerString)")
                    
                    // Check for common video formats
                    if headerString.contains("6674797071742020") || headerString.contains("667479704d534e56") {
                        print("ðŸ“¹ Detected QuickTime/MP4 format")
                    }
                }
                
                recordingCompletion?(videoData)
                
                // Clean up the temporary file
                try? FileManager.default.removeItem(at: outputFileURL)
                print("ðŸ—‘ï¸ Cleaned up temporary video file")
            } catch {
                print("âŒ Error reading video file: \(error)")
                recordingCompletion?(nil)
            }
        }
        
        recordingCompletion = nil
    }
}

// MARK: - Camera Preview

struct CameraPreview: UIViewRepresentable {
    let session: AVCaptureSession
    
    func makeUIView(context: Context) -> UIView {
        print("ðŸ–¼ï¸ Creating camera preview view")
        let view = UIView(frame: UIScreen.main.bounds)
        view.backgroundColor = UIColor.black
        
        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.frame = view.bounds
        previewLayer.videoGravity = .resizeAspectFill
        previewLayer.backgroundColor = UIColor.black.cgColor
        
        // Ensure the preview layer is ready
        if previewLayer.connection?.isEnabled == true {
            print("âœ… Preview layer connection is enabled")
        } else {
            print("âš ï¸ Preview layer connection is not enabled")
        }
        
        view.layer.addSublayer(previewLayer)
        
        print("âœ… Camera preview layer added to view")
        print("ðŸ“¹ Session running: \(session.isRunning)")
        print("ðŸ“¹ Session inputs: \(session.inputs.count)")
        print("ðŸ“¹ Session outputs: \(session.outputs.count)")
        
        // Force session to start if it's not already running and has inputs
        if !session.isRunning && session.inputs.count > 0 {
            print("ðŸ”„ Session not running but has inputs - attempting to start")
            DispatchQueue.global(qos: .background).async {
                session.startRunning()
                DispatchQueue.main.async {
                    print("âœ… Session started from preview")
                }
            }
        }
        
        return view
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {
        DispatchQueue.main.async {
            if let previewLayer = uiView.layer.sublayers?.first as? AVCaptureVideoPreviewLayer {
                previewLayer.frame = uiView.bounds
                print("ðŸ”„ Updated preview layer frame: \(uiView.bounds)")
            }
        }
    }
}